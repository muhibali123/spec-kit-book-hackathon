---
title: "Implementation and Testing"
description: "Implement the designed humanoid robot system and conduct comprehensive testing to validate functionality."
tags: ["implementation", "testing", "validation", "robotics development", "quality assurance"]
---

import { Tabs, TabItem } from '@docusaurus/theme-common';

# Implementation and Testing

## Learning Objectives

By the end of this lesson, students will be able to:
- Implement the designed humanoid robot system following best practices
- Develop comprehensive test plans for robotic systems
- Execute systematic testing procedures for different robot subsystems
- Analyze test results and identify system issues
- Document test procedures and outcomes for validation

## Key Concepts

- **Implementation Plan**: Detailed steps for building the robot system
- **Component Testing**: Verifying individual components function correctly
- **Integration Testing**: Validating that components work together
- **System Testing**: Testing the complete robot as a whole
- **Test Coverage**: Ensuring all system functions are tested
- **Safety Testing**: Verifying robot safety in all operating conditions
- **Performance Testing**: Measuring system performance against requirements
- **Regression Testing**: Ensuring changes don't break existing functionality

## Theory Summary

Implementation and testing represent the critical phase where theoretical designs become physical reality. This phase requires careful planning, systematic execution, and rigorous validation to ensure that the robot functions as intended and meets all safety and performance requirements.

The implementation plan serves as a roadmap for building the robot system, detailing the sequence of activities, required resources, and expected outcomes for each phase. A well-structured implementation plan accounts for dependencies between components, resource constraints, and potential risks.

Component testing validates individual subsystems before integration. Each component must meet its specifications and interface requirements before being integrated into the larger system. This includes functional testing, stress testing, and safety verification for each component.

Integration testing validates that components work together as designed. This involves testing interfaces, data flow, and timing between components. Integration testing is typically performed in phases, starting with closely related components and progressing to larger subsystems.

System testing validates the complete robot system against high-level requirements. This includes functional testing, performance validation, safety verification, and environmental testing. System testing ensures that the integrated system meets all specified requirements.

Test coverage ensures that all system functions are exercised during testing. This includes normal operation, edge cases, error conditions, and safety scenarios. Comprehensive test coverage is essential for identifying potential issues before deployment.

Safety testing is paramount in humanoid robotics, where robots operate in close proximity to humans. This includes emergency stop functionality, collision detection, force limiting, and safe failure modes. Safety testing must be rigorous and comprehensive.

Performance testing measures system performance against specified requirements, including speed, accuracy, endurance, and efficiency. Performance testing helps identify bottlenecks and optimization opportunities.

Regression testing ensures that changes or updates don't introduce new issues or break existing functionality. This is particularly important in iterative development where the system is continuously improved.

## Hands-on Activity

### Activity: Implement and Test a Humanoid Robot Component

In this activity, you'll implement a core component of the humanoid robot and create comprehensive tests for it.

<Tabs>
<TabItem value="python" label="Python Implementation">

```python
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Any, Callable
import random
import unittest
from dataclasses import dataclass
from enum import Enum
from datetime import datetime, timedelta
import time
import threading
import queue

class TestResult(Enum):
    """Result of a test case"""
    PASS = "PASS"
    FAIL = "FAIL"
    ERROR = "ERROR"
    SKIP = "SKIP"

class TestType(Enum):
    """Type of test being performed"""
    UNIT = "unit"
    INTEGRATION = "integration"
    SYSTEM = "system"
    SAFETY = "safety"
    PERFORMANCE = "performance"

class ComponentStatus(Enum):
    """Status of a robot component"""
    INITIALIZING = "initializing"
    READY = "ready"
    RUNNING = "running"
    ERROR = "error"
    SAFETY_LOCKOUT = "safety_lockout"

@dataclass
class TestCase:
    """Definition of a test case"""
    id: str
    name: str
    test_type: TestType
    description: str
    prerequisites: List[str]
    test_function: Callable
    expected_result: Any
    timeout: float = 10.0  # seconds
    priority: int = 1  # 1 = high, 2 = medium, 3 = low

@dataclass
class TestResultRecord:
    """Record of a test execution"""
    test_case_id: str
    result: TestResult
    execution_time: float
    timestamp: datetime
    error_message: Optional[str] = None
    measured_values: Optional[Dict] = None

class BalanceController:
    """Balance controller component for humanoid robot"""

    def __init__(self, robot_mass: float = 50.0, com_height: float = 0.8):
        self.robot_mass = robot_mass
        self.com_height = com_height
        self.status = ComponentStatus.INITIALIZING
        self.sensors = {
            'imu': {'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0, 'timestamp': datetime.now()},
            'ft_sensors': {'left_foot': [0, 0, 0], 'right_foot': [0, 0, 0], 'timestamp': datetime.now()},
            'encoders': {'hip_l': 0.0, 'hip_r': 0.0, 'knee_l': 0.0, 'knee_r': 0.0, 'timestamp': datetime.now()}
        }
        self.control_params = {
            'kp': 100.0,  # Proportional gain
            'kd': 20.0,   # Derivative gain
            'zmp_margin': 0.05,  # Safety margin for ZMP
            'max_torque': 100.0  # Maximum torque limit
        }
        self.target_com = np.array([0.0, 0.0, self.com_height])  # Center of mass target
        self.current_com = np.array([0.0, 0.0, self.com_height])
        self.com_velocity = np.array([0.0, 0.0, 0.0])
        self.control_output = np.array([0.0, 0.0])  # [hip_torque, ankle_torque]
        self.safety_limits = {
            'max_roll': 0.5,  # radians
            'max_pitch': 0.3,
            'max_com_offset': 0.1,  # meters
            'max_angular_velocity': 1.0  # rad/s
        }

        # Initialize
        self.status = ComponentStatus.READY
        print(f"Balance Controller initialized with mass={robot_mass}kg, height={com_height}m")

    def update_sensors(self, sensor_data: Dict):
        """Update sensor data from robot"""
        for sensor_type, data in sensor_data.items():
            if sensor_type in self.sensors:
                self.sensors[sensor_type].update(data)
                self.sensors[sensor_type]['timestamp'] = datetime.now()

    def compute_balance_control(self) -> np.ndarray:
        """Compute balance control torques based on current state"""
        if self.status != ComponentStatus.RUNNING:
            return np.array([0.0, 0.0])

        # Calculate center of mass position and velocity (simplified)
        imu_data = self.sensors['imu']
        current_roll = imu_data['roll']
        current_pitch = imu_data['pitch']

        # Calculate ZMP (Zero Moment Point) - simplified
        gravity = 9.81
        zmp_x = self.current_com[0] - (self.com_height * self.com_velocity[0]) / gravity
        zmp_y = self.current_com[1] - (self.com_height * self.com_velocity[1]) / gravity

        # Calculate control error
        roll_error = 0.0 - current_roll  # Target is 0
        pitch_error = 0.0 - current_pitch  # Target is 0

        # Simple PD control
        roll_control = self.control_params['kp'] * roll_error
        pitch_control = self.control_params['kd'] * pitch_error

        # Apply safety limits
        roll_control = max(-self.control_params['max_torque'],
                          min(self.control_params['max_torque'], roll_control))
        pitch_control = max(-self.control_params['max_torque'],
                           min(self.control_params['max_torque'], pitch_control))

        self.control_output = np.array([roll_control, pitch_control])

        # Update CoM estimate (simplified)
        self.current_com[0] += self.com_velocity[0] * 0.01  # 100Hz update
        self.current_com[1] += self.com_velocity[1] * 0.01

        return self.control_output

    def check_safety(self) -> Tuple[bool, List[str]]:
        """Check if system is operating within safety limits"""
        violations = []

        imu_data = self.sensors['imu']
        if abs(imu_data['roll']) > self.safety_limits['max_roll']:
            violations.append(f"Roll angle violation: {imu_data['roll']:.3f} > {self.safety_limits['max_roll']}")

        if abs(imu_data['pitch']) > self.safety_limits['max_pitch']:
            violations.append(f"Pitch angle violation: {imu_data['pitch']:.3f} > {self.safety_limits['max_pitch']}")

        com_offset = np.linalg.norm(self.current_com[:2] - self.target_com[:2])
        if com_offset > self.safety_limits['max_com_offset']:
            violations.append(f"CoM offset violation: {com_offset:.3f} > {self.safety_limits['max_com_offset']}")

        return len(violations) == 0, violations

    def emergency_stop(self):
        """Emergency stop function"""
        self.status = ComponentStatus.SAFETY_LOCKOUT
        self.control_output = np.array([0.0, 0.0])
        print("Balance Controller: Emergency stop activated!")

class TestingFramework:
    """Framework for testing robotic components"""

    def __init__(self):
        self.test_cases: List[TestCase] = []
        self.test_results: List[TestResultRecord] = []
        self.test_history: List[List[TestResultRecord]] = []
        self.current_test_run = 0

    def add_test_case(self, test_case: TestCase):
        """Add a test case to the framework"""
        self.test_cases.append(test_case)

    def run_test(self, test_case: TestCase) -> TestResultRecord:
        """Execute a single test case"""
        start_time = time.time()
        timestamp = datetime.now()

        try:
            # Check prerequisites
            for prereq in test_case.prerequisites:
                # In a real system, this would check if prerequisites are met
                pass

            # Execute test function
            result = test_case.test_function()

            # Check if result matches expected
            if result == test_case.expected_result:
                test_result = TestResult.PASS
            else:
                test_result = TestResult.FAIL

            execution_time = time.time() - start_time

            return TestResultRecord(
                test_case_id=test_case.id,
                result=test_result,
                execution_time=execution_time,
                timestamp=timestamp,
                measured_values=result if isinstance(result, dict) else None
            )

        except Exception as e:
            execution_time = time.time() - start_time
            return TestResultRecord(
                test_case_id=test_case.id,
                result=TestResult.ERROR,
                execution_time=execution_time,
                timestamp=timestamp,
                error_message=str(e)
            )

    def run_all_tests(self) -> List[TestResultRecord]:
        """Run all test cases"""
        self.current_test_run += 1
        run_results = []

        # Sort tests by priority
        sorted_tests = sorted(self.test_cases, key=lambda t: t.priority)

        for test_case in sorted_tests:
            print(f"Running test: {test_case.name} ({test_case.test_type.value})")
            result = self.run_test(test_case)
            run_results.append(result)
            self.test_results.append(result)

            # Print result
            status_icon = "✅" if result.result == TestResult.PASS else "❌"
            print(f"  {status_icon} {result.result.value} - {result.execution_time:.3f}s")

            if result.error_message:
                print(f"  Error: {result.error_message}")

        self.test_history.append(run_results)
        return run_results

    def generate_test_report(self) -> Dict[str, Any]:
        """Generate a comprehensive test report"""
        if not self.test_results:
            return {"message": "No test results available"}

        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r.result == TestResult.PASS])
        failed_tests = len([r for r in self.test_results if r.result == TestResult.FAIL])
        error_tests = len([r for r in self.test_results if r.result == TestResult.ERROR])

        # Calculate success rate by test type
        type_stats = {}
        for test_type in TestType:
            type_results = [r for r in self.test_results
                           if any(tc.test_type == test_type for tc in self.test_cases
                                 if tc.id == r.test_case_id)]
            if type_results:
                type_passed = len([r for r in type_results if r.result == TestResult.PASS])
                type_stats[test_type.value] = {
                    'total': len(type_results),
                    'passed': type_passed,
                    'success_rate': type_passed / len(type_results) if type_results else 0
                }

        # Calculate average execution time
        exec_times = [r.execution_time for r in self.test_results]
        avg_exec_time = sum(exec_times) / len(exec_times) if exec_times else 0

        return {
            'total_tests': total_tests,
            'passed': passed_tests,
            'failed': failed_tests,
            'errors': error_tests,
            'success_rate': passed_tests / total_tests if total_tests > 0 else 0,
            'average_execution_time': avg_exec_time,
            'test_type_breakdown': type_stats,
            'timestamp': datetime.now().isoformat()
        }

class HumanoidRobotTestSuite:
    """Complete test suite for humanoid robot implementation"""

    def __init__(self):
        self.framework = TestingFramework()
        self.balance_controller = BalanceController()
        self.setup_test_cases()

    def setup_test_cases(self):
        """Setup all test cases for the robot"""

        # Unit tests for balance controller
        self.framework.add_test_case(TestCase(
            id="BC-001",
            name="Balance Controller Initialization",
            test_type=TestType.UNIT,
            description="Verify balance controller initializes correctly",
            prerequisites=[],
            test_function=self.test_balance_init,
            expected_result=True,
            priority=1
        ))

        self.framework.add_test_case(TestCase(
            id="BC-002",
            name="Balance Controller Safety Check",
            test_type=TestType.SAFETY,
            description="Verify safety limits are enforced",
            prerequisites=["BC-001"],
            test_function=self.test_balance_safety,
            expected_result=(True, []),
            priority=1
        ))

        self.framework.add_test_case(TestCase(
            id="BC-003",
            name="Balance Control Computation",
            test_type=TestType.UNIT,
            description="Verify balance control algorithm works",
            prerequisites=["BC-001"],
            test_function=self.test_balance_control,
            expected_result=True,  # Function should return valid control output
            priority=2
        ))

        # Integration tests
        self.framework.add_test_case(TestCase(
            id="INT-001",
            name="Sensor Integration Test",
            test_type=TestType.INTEGRATION,
            description="Verify sensor data is properly processed",
            prerequisites=["BC-001"],
            test_function=self.test_sensor_integration,
            expected_result=True,
            priority=2
        ))

        self.framework.add_test_case(TestCase(
            id="INT-002",
            name="Control Loop Integration",
            test_type=TestType.INTEGRATION,
            description="Verify control loop executes properly",
            prerequisites=["BC-003", "INT-001"],
            test_function=self.test_control_integration,
            expected_result=True,
            priority=2
        ))

        # System tests
        self.framework.add_test_case(TestCase(
            id="SYS-001",
            name="System Stability Test",
            test_type=TestType.SYSTEM,
            description="Verify system remains stable under normal conditions",
            prerequisites=["INT-002"],
            test_function=self.test_system_stability,
            expected_result=True,
            timeout=30.0,
            priority=1
        ))

        self.framework.add_test_case(TestCase(
            id="PERF-001",
            name="Performance Under Load",
            test_type=TestType.PERFORMANCE,
            description="Verify system performance under computational load",
            prerequisites=["SYS-001"],
            test_function=self.test_performance_load,
            expected_result=True,
            priority=3
        ))

    def test_balance_init(self) -> bool:
        """Test balance controller initialization"""
        controller = BalanceController()
        return controller.status == ComponentStatus.READY

    def test_balance_safety(self) -> Tuple[bool, List[str]]:
        """Test balance controller safety checks"""
        # Simulate normal conditions
        normal_sensors = {
            'imu': {'roll': 0.1, 'pitch': 0.05, 'yaw': 0.0},
            'ft_sensors': {'left_foot': [0, 0, -250], 'right_foot': [0, 0, -250]},
            'encoders': {'hip_l': 0.0, 'hip_r': 0.0, 'knee_l': 0.0, 'knee_r': 0.0}
        }
        self.balance_controller.update_sensors(normal_sensors)
        return self.balance_controller.check_safety()

    def test_balance_control(self) -> bool:
        """Test balance control computation"""
        # Set up some sensor data
        test_sensors = {
            'imu': {'roll': 0.05, 'pitch': 0.02, 'yaw': 0.0},
            'ft_sensors': {'left_foot': [0, 0, -300], 'right_foot': [0, 0, -300]},
            'encoders': {'hip_l': 0.1, 'hip_r': -0.1, 'knee_l': 0.5, 'knee_r': 0.5}
        }
        self.balance_controller.update_sensors(test_sensors)

        control_output = self.balance_controller.compute_balance_control()
        # Check that output is reasonable (not NaN or infinite)
        return np.isfinite(control_output).all() and len(control_output) == 2

    def test_sensor_integration(self) -> bool:
        """Test sensor data integration"""
        # Simulate sensor data flow
        for i in range(10):  # 10 sensor updates
            sensor_data = {
                'imu': {
                    'roll': random.uniform(-0.1, 0.1),
                    'pitch': random.uniform(-0.1, 0.1),
                    'yaw': random.uniform(-0.1, 0.1)
                },
                'ft_sensors': {
                    'left_foot': [random.uniform(-10, 10), random.uniform(-10, 10), random.uniform(-400, -200)],
                    'right_foot': [random.uniform(-10, 10), random.uniform(-10, 10), random.uniform(-400, -200)]
                },
                'encoders': {
                    'hip_l': random.uniform(-0.5, 0.5),
                    'hip_r': random.uniform(-0.5, 0.5),
                    'knee_l': random.uniform(0, 1),
                    'knee_r': random.uniform(0, 1)
                }
            }
            self.balance_controller.update_sensors(sensor_data)

            # Verify data was updated
            if self.balance_controller.sensors['imu']['timestamp'] is None:
                return False

        return True

    def test_control_integration(self) -> bool:
        """Test control loop integration"""
        # Run a simple control loop
        for i in range(20):  # 20 control cycles
            # Update with some sensor data
            sensor_data = {
                'imu': {
                    'roll': random.uniform(-0.05, 0.05),
                    'pitch': random.uniform(-0.05, 0.05),
                    'yaw': 0.0
                },
                'ft_sensors': {
                    'left_foot': [0, 0, -250],
                    'right_foot': [0, 0, -250]
                },
                'encoders': {
                    'hip_l': 0.0,
                    'hip_r': 0.0,
                    'knee_l': 0.5,
                    'knee_r': 0.5
                }
            }
            self.balance_controller.update_sensors(sensor_data)
            self.balance_controller.status = ComponentStatus.RUNNING

            # Compute control
            control_output = self.balance_controller.compute_balance_control()

            # Check for safety violations
            is_safe, violations = self.balance_controller.check_safety()
            if not is_safe:
                print(f"Control integration safety violation: {violations}")
                return False

        return True

    def test_system_stability(self) -> bool:
        """Test system stability over time"""
        start_time = time.time()
        max_duration = 10.0  # Test for 10 seconds

        self.balance_controller.status = ComponentStatus.RUNNING

        while time.time() - start_time < max_duration:
            # Simulate normal walking conditions
            sensor_data = {
                'imu': {
                    'roll': random.uniform(-0.05, 0.05),
                    'pitch': random.uniform(-0.03, 0.03),
                    'yaw': random.uniform(-0.01, 0.01)
                },
                'ft_sensors': {
                    'left_foot': [random.uniform(-20, 20), random.uniform(-20, 20), random.uniform(-350, -250)],
                    'right_foot': [random.uniform(-20, 20), random.uniform(-20, 20), random.uniform(-350, -250)]
                },
                'encoders': {
                    'hip_l': random.uniform(-0.2, 0.2),
                    'hip_r': random.uniform(-0.2, 0.2),
                    'knee_l': random.uniform(0.3, 0.7),
                    'knee_r': random.uniform(0.3, 0.7)
                }
            }

            self.balance_controller.update_sensors(sensor_data)
            control_output = self.balance_controller.compute_balance_control()
            is_safe, violations = self.balance_controller.check_safety()

            if not is_safe:
                print(f"Stability test failed due to safety violation: {violations}")
                return False

            time.sleep(0.01)  # 100Hz control loop simulation

        return True

    def test_performance_load(self) -> bool:
        """Test performance under computational load"""
        start_time = time.time()

        # Simulate high load by running many calculations
        for i in range(100):
            # Perform intensive calculations
            large_matrix = np.random.rand(100, 100)
            result = np.linalg.inv(large_matrix + np.eye(100) * 0.1)  # Regularized inverse

            # During this, keep running control loop
            sensor_data = {
                'imu': {'roll': 0.01, 'pitch': 0.01, 'yaw': 0.0},
                'ft_sensors': {'left_foot': [0, 0, -250], 'right_foot': [0, 0, -250]},
                'encoders': {'hip_l': 0.0, 'hip_r': 0.0, 'knee_l': 0.5, 'knee_r': 0.5}
            }
            self.balance_controller.update_sensors(sensor_data)
            control_output = self.balance_controller.compute_balance_control()

            # Check that control output is still reasonable
            if not np.isfinite(control_output).all():
                return False

        end_time = time.time()
        execution_time = end_time - start_time

        # Check that execution time is reasonable (less than 5 seconds for this test)
        return execution_time < 5.0

def run_robot_testing():
    """Run comprehensive testing of the humanoid robot implementation"""
    print("Humanoid Robot Implementation and Testing")
    print("=" * 42)

    # Create test suite
    test_suite = HumanoidRobotTestSuite()

    print(f"\nTest Suite Setup:")
    print(f"- Total test cases: {len(test_suite.framework.test_cases)}")
    print(f"- Test types: {[t.test_type.value for t in set(tc.test_type for tc in test_suite.framework.test_cases)]}")

    # Run all tests
    print(f"\nRunning all tests...")
    results = test_suite.framework.run_all_tests()

    # Generate and display report
    print(f"\nTest Report:")
    print("-" * 12)
    report = test_suite.framework.generate_test_report()

    print(f"Total Tests: {report['total_tests']}")
    print(f"Passed: {report['passed']}")
    print(f"Failed: {report['failed']}")
    print(f"Errors: {report['errors']}")
    print(f"Success Rate: {report['success_rate']:.2%}")
    print(f"Avg Execution Time: {report['average_execution_time']:.3f}s")

    # Breakdown by test type
    print(f"\nTest Type Breakdown:")
    for test_type, stats in report['test_type_breakdown'].items():
        print(f"  {test_type}: {stats['passed']}/{stats['total']} ({stats['success_rate']:.1%})")

    # Show detailed results
    print(f"\nDetailed Test Results:")
    print("-" * 20)
    for result in results:
        test_case = next((tc for tc in test_suite.framework.test_cases if tc.id == result.test_case_id), None)
        status_icon = "✅" if result.result == TestResult.PASS else "❌" if result.result in [TestResult.FAIL, TestResult.ERROR] else "⚠️"
        print(f"{status_icon} {test_case.name if test_case else result.test_case_id}: {result.result.value}")
        if result.error_message:
            print(f"    Error: {result.error_message}")

    # Identify failing tests and suggest fixes
    failing_tests = [r for r in results if r.result in [TestResult.FAIL, TestResult.ERROR]]
    if failing_tests:
        print(f"\nFailing Tests - Recommended Actions:")
        print("-" * 35)
        for result in failing_tests:
            test_case = next((tc for tc in test_suite.framework.test_cases if tc.id == result.test_case_id), None)
            print(f"• {test_case.name if test_case else result.test_case_id}:")
            if result.error_message and "safety" in result.error_message.lower():
                print("  - Check safety parameter limits")
                print("  - Verify sensor calibration")
            elif result.error_message and "control" in result.error_message.lower():
                print("  - Review control algorithm parameters")
                print("  - Check sensor data validity")
            else:
                print("  - Review test conditions and expected results")
                print("  - Verify component implementation")

    # Performance analysis
    print(f"\nPerformance Analysis:")
    print("-" * 19)
    execution_times = [r.execution_time for r in results]
    if execution_times:
        print(f"Fastest test: {min(execution_times):.4f}s")
        print(f"Slowest test: {max(execution_times):.4f}s")
        print(f"Average test time: {sum(execution_times)/len(execution_times):.4f}s")

    # Visualization
    plt.figure(figsize=(15, 10))

    # Plot 1: Test results by type
    plt.subplot(2, 3, 1)
    test_types = [tc.test_type.value for tc in test_suite.framework.test_cases]
    unique_types = list(set(test_types))
    type_results = []
    for test_type in unique_types:
        type_tests = [tc for tc in test_suite.framework.test_cases if tc.test_type.value == test_type]
        type_result_ids = [r.test_case_id for r in results]
        type_results_count = []
        for tt in type_tests:
            if tt.id in type_result_ids:
                res = next((r.result for r in results if r.test_case_id == tt.id), None)
                type_results_count.append(res.value if res else 'unknown')

        pass_count = type_results_count.count('PASS')
        fail_count = type_results_count.count('FAIL')
        error_count = type_results_count.count('ERROR')

        plt.bar([f"{test_type}\nPass", f"{test_type}\nFail", f"{test_type}\nError"],
                [pass_count, fail_count, error_count])

    plt.title('Test Results by Type')
    plt.ylabel('Number of Tests')
    plt.xticks(rotation=45)

    # Plot 2: Execution time distribution
    plt.subplot(2, 3, 2)
    plt.hist(execution_times, bins=10, alpha=0.7)
    plt.title('Test Execution Time Distribution')
    plt.xlabel('Execution Time (s)')
    plt.ylabel('Number of Tests')

    # Plot 3: Test success rate over time
    plt.subplot(2, 3, 3)
    cumulative_success = []
    running_success = 0
    for result in results:
        if result.result == TestResult.PASS:
            running_success += 1
        cumulative_success.append(running_success / len(cumulative_success) if cumulative_success else 0)

    plt.plot(range(1, len(cumulative_success) + 1), cumulative_success, marker='o')
    plt.title('Cumulative Success Rate')
    plt.xlabel('Test Number')
    plt.ylabel('Success Rate')
    plt.grid(True, alpha=0.3)

    # Plot 4: Test types distribution
    plt.subplot(2, 3, 4)
    type_counts = {}
    for test_type in TestType:
        count = len([tc for tc in test_suite.framework.test_cases if tc.test_type == test_type])
        if count > 0:
            type_counts[test_type.value] = count

    plt.pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')
    plt.title('Test Type Distribution')

    # Plot 5: Test priority distribution
    plt.subplot(2, 3, 5)
    priorities = [tc.priority for tc in test_suite.framework.test_cases]
    priority_labels = ['High (1)', 'Medium (2)', 'Low (3)']
    priority_counts = [priorities.count(1), priorities.count(2), priorities.count(3)]
    plt.bar(priority_labels, priority_counts)
    plt.title('Test Priority Distribution')
    plt.ylabel('Number of Tests')

    # Plot 6: Results summary
    plt.subplot(2, 3, 6)
    result_counts = {}
    for result_type in TestResult:
        count = len([r for r in results if r.result == result_type])
        result_counts[result_type.value] = count

    colors = ['green' if k == 'PASS' else 'red' if k in ['FAIL', 'ERROR'] else 'orange' for k in result_counts.keys()]
    plt.bar(result_counts.keys(), result_counts.values(), color=colors)
    plt.title('Test Results Summary')
    plt.ylabel('Number of Tests')

    plt.tight_layout()
    plt.show()

    print(f"\nImplementation and testing completed!")
    print(f"The test suite provides comprehensive validation of the robot system.")

# Run the testing framework
run_robot_testing()
```

</TabItem>
</Tabs>

## Tools & Components Required

- Python 3.7 or higher
- NumPy for numerical computations
- Matplotlib for visualization
- Basic understanding of testing frameworks and methodologies
- Knowledge of robotics validation and verification

## Step-by-Step Instructions

1. **Design Test Framework**: Create a comprehensive testing framework for robotic components
2. **Implement Component**: Build the component to be tested (e.g., balance controller)
3. **Create Test Cases**: Define unit, integration, system, safety, and performance tests
4. **Execute Tests**: Run all tests systematically and record results
5. **Analyze Results**: Evaluate test outcomes and identify issues
6. **Generate Reports**: Create comprehensive test reports
7. **Visualize Results**: Show test results and performance metrics

## Code Snippets

### Test Case Framework

```python
@dataclass
class TestCase:
    """Definition of a test case"""
    id: str
    name: str
    test_type: TestType
    description: str
    prerequisites: List[str]
    test_function: Callable
    expected_result: Any
    timeout: float = 10.0  # seconds
    priority: int = 1  # 1 = high, 2 = medium, 3 = low

class TestingFramework:
    """Framework for testing robotic components"""

    def __init__(self):
        self.test_cases: List[TestCase] = []
        self.test_results: List[TestResultRecord] = []
        self.test_history: List[List[TestResultRecord]] = []
        self.current_test_run = 0

    def add_test_case(self, test_case: TestCase):
        """Add a test case to the framework"""
        self.test_cases.append(test_case)

    def run_test(self, test_case: TestCase) -> TestResultRecord:
        """Execute a single test case"""
        start_time = time.time()
        timestamp = datetime.now()

        try:
            # Check prerequisites
            for prereq in test_case.prerequisites:
                # In a real system, this would check if prerequisites are met
                pass

            # Execute test function
            result = test_case.test_function()

            # Check if result matches expected
            if result == test_case.expected_result:
                test_result = TestResult.PASS
            else:
                test_result = TestResult.FAIL

            execution_time = time.time() - start_time

            return TestResultRecord(
                test_case_id=test_case.id,
                result=test_result,
                execution_time=execution_time,
                timestamp=timestamp,
                measured_values=result if isinstance(result, dict) else None
            )

        except Exception as e:
            execution_time = time.time() - start_time
            return TestResultRecord(
                test_case_id=test_case.id,
                result=TestResult.ERROR,
                execution_time=execution_time,
                timestamp=timestamp,
                error_message=str(e)
            )
```

### Component Testing Implementation

```python
class BalanceController:
    """Balance controller component for humanoid robot"""

    def __init__(self, robot_mass: float = 50.0, com_height: float = 0.8):
        self.robot_mass = robot_mass
        self.com_height = com_height
        self.status = ComponentStatus.INITIALIZING
        self.sensors = {
            'imu': {'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0, 'timestamp': datetime.now()},
            'ft_sensors': {'left_foot': [0, 0, 0], 'right_foot': [0, 0, 0], 'timestamp': datetime.now()},
            'encoders': {'hip_l': 0.0, 'hip_r': 0.0, 'knee_l': 0.0, 'knee_r': 0.0, 'timestamp': datetime.now()}
        }
        self.control_params = {
            'kp': 100.0,  # Proportional gain
            'kd': 20.0,   # Derivative gain
            'zmp_margin': 0.05,  # Safety margin for ZMP
            'max_torque': 100.0  # Maximum torque limit
        }
        # Additional initialization...

    def compute_balance_control(self) -> np.ndarray:
        """Compute balance control torques based on current state"""
        if self.status != ComponentStatus.RUNNING:
            return np.array([0.0, 0.0])

        # Calculate center of mass position and velocity (simplified)
        imu_data = self.sensors['imu']
        current_roll = imu_data['roll']
        current_pitch = imu_data['pitch']

        # Calculate ZMP (Zero Moment Point) - simplified
        gravity = 9.81
        zmp_x = self.current_com[0] - (self.com_height * self.com_velocity[0]) / gravity
        zmp_y = self.current_com[1] - (self.com_height * self.com_velocity[1]) / gravity

        # Calculate control error
        roll_error = 0.0 - current_roll  # Target is 0
        pitch_error = 0.0 - current_pitch  # Target is 0

        # Simple PD control
        roll_control = self.control_params['kp'] * roll_error
        pitch_control = self.control_params['kd'] * pitch_error

        # Apply safety limits
        roll_control = max(-self.control_params['max_torque'],
                          min(self.control_params['max_torque'], roll_control))
        pitch_control = max(-self.control_params['max_torque'],
                           min(self.control_params['max_torque'], pitch_control))

        self.control_output = np.array([roll_control, pitch_control])

        # Update CoM estimate (simplified)
        self.current_com[0] += self.com_velocity[0] * 0.01  # 100Hz update
        self.current_com[1] += self.com_velocity[1] * 0.01

        return self.control_output
```

## Review Questions

1. What are the different types of testing required for robotic systems?
2. How do you prioritize test cases in a robotic system validation?
3. What is the difference between unit, integration, and system testing?
4. Why is safety testing critical in humanoid robotics?
5. How do you measure test coverage in robotic systems?

## Mini Assessment

<Tabs>
<TabItem value="question1" label="Question 1">

**What is the primary purpose of integration testing in robotics?**

A) To test individual components separately
B) To validate that components work together as designed
C) To test the robot's appearance
D) To measure manufacturing costs

<details>
<summary>Answer</summary>
B) To validate that components work together as designed - Integration testing validates that components function correctly when connected and interacting.
</details>

</TabItem>

<TabItem value="question2" label="Question 2">

**Why is safety testing particularly important in humanoid robotics?**

A) To make robots faster
B) Because humanoid robots operate in close proximity to humans and safety is paramount
C) To reduce robot cost
D) To improve robot appearance

<details>
<summary>Answer</summary>
B) Because humanoid robots operate in close proximity to humans and safety is paramount - Safety testing ensures robots can operate safely around humans.
</details>

</TabItem>
</Tabs>

## Practical Task

Extend the testing framework to include hardware-in-the-loop (HIL) testing capabilities. Implement a system that can connect to actual robot hardware for testing while maintaining safety protocols. Create tests that validate the interaction between software algorithms and real hardware components.

## Expected Outcomes

After completing this lesson, you should be able to:
- Implement comprehensive testing frameworks for robotic systems
- Design and execute unit, integration, and system tests
- Analyze test results and identify system issues
- Validate robot safety and performance requirements
- Document testing procedures and outcomes