---
title: "Real-time Control and Optimization"
description: "Explore how humanoid robots achieve real-time performance in control systems while maintaining optimization objectives."
tags: ["real-time control", "optimization", "control systems", "humanoid robotics", "performance"]
---

import { Tabs, TabItem } from '@docusaurus/theme-common';

# Real-time Control and Optimization

## Learning Objectives

By the end of this lesson, students will be able to:
- Understand the requirements and constraints of real-time control systems
- Implement optimization techniques suitable for real-time applications
- Analyze the trade-offs between optimality and computational efficiency
- Design control systems that meet real-time performance requirements
- Evaluate different approaches to achieving real-time performance in robotics

## Key Concepts

- **Real-time Systems**: Systems that must respond to inputs within strict time constraints
- **Hard Real-time**: Systems where missing a deadline is equivalent to a system failure
- **Soft Real-time**: Systems where occasional deadline misses are acceptable
- **Control Loop Timing**: The time constraints for executing control algorithms
- **Computational Complexity**: The processing requirements of control algorithms
- **Model Predictive Control (MPC)**: Optimization-based control with computational challenges
- **Approximation Techniques**: Methods to reduce computational load while maintaining performance
- **Parallel Processing**: Using multiple processors to accelerate computations

## Theory Summary

Real-time control is a critical requirement for humanoid robots, where control actions must be computed and applied within strict timing constraints to maintain stability and achieve desired behaviors. The challenge lies in balancing optimal control performance with the computational limitations of real-time systems.

In humanoid robotics, real-time constraints typically range from 1 millisecond for low-level joint control to 10-50 milliseconds for high-level motion planning. These constraints are driven by the robot's dynamics and the need to maintain stability. For example, a humanoid robot standing on one foot might need control updates every few milliseconds to maintain balance.

Hard real-time systems have strict deadlines where missing a deadline results in system failure. In humanoid robotics, this might apply to balance control where missing a control update could cause the robot to fall. Soft real-time systems allow occasional deadline misses, which might apply to higher-level planning tasks.

The computational complexity of control algorithms directly impacts their real-time feasibility. Model Predictive Control (MPC), while powerful, can be computationally intensive due to the optimization problem that must be solved at each time step. This makes it challenging to implement MPC in real-time systems without careful algorithm design and implementation.

Approximation techniques can significantly reduce computational requirements while maintaining acceptable performance. These might include linearization of nonlinear models, simplified optimization algorithms, or reduced prediction horizons. The key is to understand the trade-offs between optimality and computational efficiency.

Pre-computation and caching can move computationally expensive operations outside the real-time control loop. For example, complex optimization problems can be solved offline for different operating conditions, with the solutions stored in lookup tables for real-time access.

Parallel processing allows computationally intensive tasks to be distributed across multiple processing units. Modern humanoid robots often use a combination of CPUs, GPUs, and specialized hardware to achieve real-time performance for complex control algorithms.

Model reduction techniques simplify complex system models while preserving the essential dynamics needed for control. This can dramatically reduce the computational load of model-based control algorithms while maintaining performance.

## Hands-on Activity

### Activity: Implementing Real-time Optimized Control with Performance Monitoring

In this activity, you'll create a real-time control system that monitors performance and adjusts its optimization strategy to maintain real-time operation.

<Tabs>
<TabItem value="python" label="Python Implementation">

```python
import numpy as np
import matplotlib.pyplot as plt
import time
from typing import Dict, List, Tuple, Callable
from scipy.optimize import minimize, minimize_scalar
import threading
import queue
import random

class RealTimeController:
    """A controller that adapts its optimization strategy based on timing constraints"""

    def __init__(self, target_frequency: float = 100.0,  # 100 Hz
                 max_computation_time: float = 0.008):  # 8ms max computation time
        self.target_frequency = target_frequency
        self.target_period = 1.0 / target_frequency
        self.max_computation_time = max_computation_time
        self.timing_history = []
        self.optimization_level = 2  # 0=low, 1=medium, 2=high optimization

        # Control system parameters
        self.A = np.array([[1.0, 0.01], [0.1, 0.99]])  # State transition matrix
        self.B = np.array([[0.0], [1.0]])               # Control input matrix
        self.Q = np.array([[10.0, 0.0], [0.0, 1.0]])    # State cost matrix
        self.R = np.array([[1.0]])                      # Control cost matrix

    def compute_low_optimization(self, state: np.ndarray,
                                reference: np.ndarray) -> np.ndarray:
        """Fast but less optimal control computation"""
        # Simple state feedback control
        K_simple = np.array([2.0, 1.0])  # Pre-computed simple gain
        error = reference - state
        control = K_simple @ error
        return np.array([control])

    def compute_medium_optimization(self, state: np.ndarray,
                                   reference: np.ndarray) -> np.ndarray:
        """Medium complexity optimization"""
        # Linear Quadratic Regulator (LQR) approach
        # For this example, we'll use a simplified LQR computation
        K = np.array([5.0, 2.0])  # LQR gain (would be computed from ARE in real implementation)
        error = reference - state
        control = K @ error
        return np.array([control])

    def compute_high_optimization(self, state: np.ndarray,
                                 reference: np.ndarray) -> np.ndarray:
        """Full optimization computation"""
        # Model Predictive Control with short horizon
        horizon = 5
        n_states = len(state)
        n_controls = 1

        def mpc_cost(control_sequence):
            """Cost function for MPC optimization"""
            total_cost = 0
            current_state = state.copy()

            for k in range(horizon):
                # Predict next state
                u = control_sequence[k] if k < len(control_sequence) else 0
                next_state = self.A @ current_state + self.B.flatten() * u

                # State cost
                state_error = reference - next_state
                state_cost = state_error.T @ self.Q @ state_error
                total_cost += state_cost

                # Control cost
                control_cost = u * self.R[0, 0] * u
                total_cost += control_cost

                current_state = next_state

            return total_cost

        # Initial guess for control sequence
        initial_controls = np.zeros(horizon)

        # Optimize control sequence
        try:
            result = minimize(
                mpc_cost,
                initial_controls,
                method='BFGS',
                options={'maxiter': 20}  # Limit iterations for real-time
            )
            optimal_controls = result.x
            return np.array([optimal_controls[0]])  # Return first control
        except:
            # Fallback to medium optimization if MPC fails
            return self.compute_medium_optimization(state, reference)

    def adapt_optimization_level(self, computation_time: float):
        """Adapt optimization level based on computation time"""
        # If computation took too long, reduce optimization level
        if computation_time > self.max_computation_time * 0.8:  # 80% of max time
            self.optimization_level = max(0, self.optimization_level - 1)
        # If computation was fast and we're not at max level, increase it
        elif computation_time < self.max_computation_time * 0.3 and self.optimization_level < 2:
            self.optimization_level = min(2, self.optimization_level + 1)

    def control(self, state: np.ndarray, reference: np.ndarray) -> Tuple[np.ndarray, float]:
        """Compute control action with timing monitoring"""
        start_time = time.time()

        if self.optimization_level == 0:
            control = self.compute_low_optimization(state, reference)
        elif self.optimization_level == 1:
            control = self.compute_medium_optimization(state, reference)
        else:
            control = self.compute_high_optimization(state, reference)

        computation_time = time.time() - start_time

        # Adapt optimization level based on timing
        self.adapt_optimization_level(computation_time)

        # Store timing information
        self.timing_history.append({
            'computation_time': computation_time,
            'optimization_level': self.optimization_level,
            'target_time': self.max_computation_time
        })

        return control, computation_time

class PerformanceMonitor:
    """Monitors and visualizes real-time performance"""

    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.control_history = []
        self.state_history = []
        self.reference_history = []
        self.timing_data = []

    def update(self, state: np.ndarray, reference: np.ndarray,
               control: np.ndarray, timing_info: Dict):
        """Update performance data"""
        self.state_history.append(state.copy())
        self.reference_history.append(reference.copy())
        self.control_history.append(control.copy())
        self.timing_data.append(timing_info.copy())

        # Maintain window size
        if len(self.state_history) > self.window_size:
            self.state_history.pop(0)
            self.reference_history.pop(0)
            self.control_history.pop(0)
            self.timing_data.pop(0)

    def get_performance_metrics(self) -> Dict:
        """Calculate performance metrics"""
        if len(self.state_history) < 2:
            return {}

        states = np.array(self.state_history)
        references = np.array(self.reference_history)
        controls = np.array(self.control_history)

        # Calculate tracking error
        errors = states - references
        rmse = np.sqrt(np.mean(errors**2))
        max_error = np.max(np.abs(errors))

        # Calculate control effort
        avg_control = np.mean(np.abs(controls))
        max_control = np.max(np.abs(controls))

        # Calculate timing statistics
        if self.timing_data:
            comp_times = [t['computation_time'] for t in self.timing_data]
            avg_time = np.mean(comp_times)
            max_time = np.max(comp_times)
            timing_violations = sum(1 for t in comp_times if t > 0.008)  # 8ms limit
        else:
            avg_time = 0
            max_time = 0
            timing_violations = 0

        return {
            'rmse': rmse,
            'max_error': max_error,
            'avg_control': avg_control,
            'max_control': max_control,
            'avg_computation_time': avg_time,
            'max_computation_time': max_time,
            'timing_violations': timing_violations,
            'optimization_level': self.timing_data[-1]['optimization_level'] if self.timing_data else 0
        }

class RealTimeSimulation:
    """Simulates real-time control with timing constraints"""

    def __init__(self):
        self.controller = RealTimeController(target_frequency=100.0)
        self.monitor = PerformanceMonitor(window_size=200)

        # System state (position, velocity)
        self.state = np.array([1.0, 0.1])  # Start with some initial error
        self.dt = 0.01  # 100 Hz simulation
        self.time = 0.0

    def simulate_step(self, reference: np.ndarray) -> Dict:
        """Execute one simulation step with real-time constraints"""
        # Compute control with timing constraints
        control, comp_time = self.controller.control(self.state, reference)

        # Apply control to system dynamics
        # Simple second-order system: x'' = u
        acceleration = control[0]  # Control directly affects acceleration
        self.state[1] += acceleration * self.dt  # Update velocity
        self.state[0] += self.state[1] * self.dt  # Update position

        # Add small process noise to make simulation more realistic
        self.state += np.random.normal(0, 0.001, size=self.state.shape)

        # Update monitor
        timing_info = {
            'computation_time': comp_time,
            'optimization_level': self.controller.optimization_level,
            'target_time': self.controller.max_computation_time
        }
        self.monitor.update(self.state, reference, control, timing_info)

        self.time += self.dt

        return {
            'state': self.state.copy(),
            'control': control.copy(),
            'computation_time': comp_time,
            'optimization_level': self.controller.optimization_level
        }

def run_real_time_simulation():
    """Run simulation demonstrating real-time control with optimization adaptation"""
    print("Real-time Control and Optimization Simulation")
    print("=" * 50)

    # Initialize simulation
    sim = RealTimeSimulation()

    # Define reference trajectory (step changes)
    def get_reference(t):
        if t < 2.0:
            return np.array([0.0, 0.0])  # Start at origin
        elif t < 4.0:
            return np.array([1.0, 0.0])  # Move to position 1
        elif t < 6.0:
            return np.array([0.5, 0.0])  # Move to position 0.5
        else:
            return np.array([-0.5, 0.0]) # Move to position -0.5

    # Simulation parameters
    simulation_time = 8.0
    steps = int(simulation_time / sim.dt)

    print("Time\tState[0]\tControl\tCompTime\tOptLevel")
    print("-" * 55)

    for i in range(steps):
        t = i * sim.dt
        reference = get_reference(t)

        # Execute simulation step
        result = sim.simulate_step(reference)

        # Print status every 100 steps
        if i % 100 == 0:
            print(f"{t:4.1f}\t{result['state'][0]:7.3f}\t{result['control'][0]:7.3f}\t"
                  f"{result['computation_time']*1000:6.2f}ms\t{result['optimization_level']}")

    # Get performance metrics
    metrics = sim.monitor.get_performance_metrics()

    print(f"\nPerformance Metrics:")
    print(f"  RMSE: {metrics.get('rmse', 0):.4f}")
    print(f"  Max Error: {metrics.get('max_error', 0):.4f}")
    print(f"  Avg Control Effort: {metrics.get('avg_control', 0):.4f}")
    print(f"  Avg Computation Time: {metrics.get('avg_computation_time', 0)*1000:.2f}ms")
    print(f"  Timing Violations: {metrics.get('timing_violations', 0)}")
    print(f"  Final Optimization Level: {metrics.get('optimization_level', 0)}")

    # Create visualization
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

    # Plot 1: State tracking
    states = np.array(sim.monitor.state_history)
    references = np.array(sim.monitor.reference_history)
    times = np.arange(len(states)) * sim.dt

    ax1.plot(times, states[:, 0], 'b-', linewidth=2, label='Actual Position')
    ax1.plot(times, references[:, 0], 'r--', linewidth=2, label='Reference Position')
    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Position')
    ax1.set_title('State Tracking Performance')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: Control effort
    controls = np.array(sim.monitor.control_history)
    ax2.plot(times, controls[:, 0], 'g-', linewidth=2)
    ax2.set_xlabel('Time (s)')
    ax2.set_ylabel('Control Input')
    ax2.set_title('Control Effort Over Time')
    ax2.grid(True, alpha=0.3)

    # Plot 3: Computation time
    comp_times = [t['computation_time'] * 1000 for t in sim.monitor.timing_data]  # Convert to ms
    opt_levels = [t['optimization_level'] for t in sim.monitor.timing_data]

    ax3_twin = ax3.twinx()
    ax3.plot(times, comp_times, 'b-', linewidth=2, label='Computation Time')
    ax3_twin.plot(times, opt_levels, 'r--', linewidth=2, label='Optimization Level')

    ax3.set_xlabel('Time (s)')
    ax3.set_ylabel('Computation Time (ms)', color='b')
    ax3_twin.set_ylabel('Optimization Level', color='r')
    ax3.set_title('Computation Time and Optimization Level')
    ax3.grid(True, alpha=0.3)

    # Add legend for both y-axes
    lines1, labels1 = ax3.get_legend_handles_labels()
    lines2, labels2 = ax3_twin.get_legend_handles_labels()
    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

    # Plot 4: Error over time
    errors = states - references
    ax4.plot(times, errors[:, 0], 'r-', linewidth=2)
    ax4.axhline(y=0, color='k', linestyle='--', alpha=0.5)
    ax4.set_xlabel('Time (s)')
    ax4.set_ylabel('Tracking Error')
    ax4.set_title('Tracking Error Over Time')
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("\nReal-time control simulation completed!")
    print("The controller adapted its optimization strategy based on timing constraints.")

    return sim

# Run the simulation
sim = run_real_time_simulation()
```

</TabItem>
</Tabs>

## Tools & Components Required

- Python 3.7 or higher
- NumPy for numerical computations
- SciPy for optimization algorithms
- Matplotlib for visualization
- Basic understanding of real-time systems and optimization
- Knowledge of control theory and system dynamics

## Step-by-Step Instructions

1. **Design Real-time Controller**: Create a controller that monitors its own computation time
2. **Implement Optimization Levels**: Create different optimization strategies with varying computational complexity
3. **Add Adaptation Logic**: Implement logic to adjust optimization based on timing constraints
4. **Create Performance Monitor**: Build a system to track timing and performance metrics
5. **Simulate Real-time Operation**: Test the system with timing constraints and changing conditions
6. **Visualize Performance**: Show how the system adapts to maintain real-time operation
7. **Analyze Trade-offs**: Evaluate the balance between optimality and computational efficiency

## Code Snippets

### Adaptive Optimization Level Control

```python
class RealTimeController:
    """A controller that adapts its optimization strategy based on timing constraints"""

    def __init__(self, target_frequency: float = 100.0,  # 100 Hz
                 max_computation_time: float = 0.008):  # 8ms max computation time
        self.target_frequency = target_frequency
        self.target_period = 1.0 / target_frequency
        self.max_computation_time = max_computation_time
        self.timing_history = []
        self.optimization_level = 2  # 0=low, 1=medium, 2=high optimization

    def adapt_optimization_level(self, computation_time: float):
        """Adapt optimization level based on computation time"""
        # If computation took too long, reduce optimization level
        if computation_time > self.max_computation_time * 0.8:  # 80% of max time
            self.optimization_level = max(0, self.optimization_level - 1)
        # If computation was fast and we're not at max level, increase it
        elif computation_time < self.max_computation_time * 0.3 and self.optimization_level < 2:
            self.optimization_level = min(2, self.optimization_level + 1)

    def control(self, state: np.ndarray, reference: np.ndarray) -> Tuple[np.ndarray, float]:
        """Compute control action with timing monitoring"""
        start_time = time.time()

        if self.optimization_level == 0:
            control = self.compute_low_optimization(state, reference)
        elif self.optimization_level == 1:
            control = self.compute_medium_optimization(state, reference)
        else:
            control = self.compute_high_optimization(state, reference)

        computation_time = time.time() - start_time

        # Adapt optimization level based on timing
        self.adapt_optimization_level(computation_time)

        # Store timing information
        self.timing_history.append({
            'computation_time': computation_time,
            'optimization_level': self.optimization_level,
            'target_time': self.max_computation_time
        })

        return control, computation_time
```

### Multi-Level Optimization Implementation

```python
def compute_low_optimization(self, state: np.ndarray,
                            reference: np.ndarray) -> np.ndarray:
    """Fast but less optimal control computation"""
    # Simple state feedback control
    K_simple = np.array([2.0, 1.0])  # Pre-computed simple gain
    error = reference - state
    control = K_simple @ error
    return np.array([control])

def compute_medium_optimization(self, state: np.ndarray,
                               reference: np.ndarray) -> np.ndarray:
    """Medium complexity optimization"""
    # Linear Quadratic Regulator (LQR) approach
    K = np.array([5.0, 2.0])  # LQR gain (would be computed from ARE in real implementation)
    error = reference - state
    control = K @ error
    return np.array([control])

def compute_high_optimization(self, state: np.ndarray,
                             reference: np.ndarray) -> np.ndarray:
    """Full optimization computation"""
    # Model Predictive Control with short horizon
    horizon = 5
    n_states = len(state)
    n_controls = 1

    def mpc_cost(control_sequence):
        """Cost function for MPC optimization"""
        total_cost = 0
        current_state = state.copy()

        for k in range(horizon):
            # Predict next state
            u = control_sequence[k] if k < len(control_sequence) else 0
            next_state = self.A @ current_state + self.B.flatten() * u

            # State cost
            state_error = reference - next_state
            state_cost = state_error.T @ self.Q @ state_error
            total_cost += state_cost

            # Control cost
            control_cost = u * self.R[0, 0] * u
            total_cost += control_cost

            current_state = next_state

        return total_cost

    # Initial guess for control sequence
    initial_controls = np.zeros(horizon)

    # Optimize control sequence
    try:
        result = minimize(
            mpc_cost,
            initial_controls,
            method='BFGS',
            options={'maxiter': 20}  # Limit iterations for real-time
        )
        optimal_controls = result.x
        return np.array([optimal_controls[0]])  # Return first control
    except:
        # Fallback to medium optimization if MPC fails
        return self.compute_medium_optimization(state, reference)
```

## Review Questions

1. What are the key differences between hard and soft real-time systems in robotics?
2. How does computational complexity affect real-time control performance?
3. What are some techniques to reduce the computational load of optimization algorithms?
4. How can control systems adapt their behavior based on timing constraints?
5. What are the trade-offs between optimality and real-time performance?

## Mini Assessment

<Tabs>
<TabItem value="question1" label="Question 1">

**What is the main challenge in implementing Model Predictive Control (MPC) in real-time systems?**

A) Too much memory usage
B) High computational complexity of optimization problems
C) Difficulty in system modeling
D) Need for special hardware

<details>
<summary>Answer</summary>
B) High computational complexity of optimization problems - MPC requires solving optimization problems at each time step, which can be computationally intensive for real-time operation.
</details>

</TabItem>

<TabItem value="question2" label="Question 2">

**What characterizes a hard real-time system?**

A) Occasional deadline misses are acceptable
B) Missing a deadline is equivalent to system failure
C) It operates faster than soft real-time
D) It uses more computational resources

<details>
<summary>Answer</summary>
B) Missing a deadline is equivalent to system failure - In hard real-time systems, meeting deadlines is critical for correct system operation.
</details>

</TabItem>
</Tabs>

## Practical Task

Extend the real-time controller to implement a multi-threaded architecture where optimization computations are performed in the background while the system operates with the best available solution. Implement a system where the control thread can use a suboptimal solution if the optimal one is not ready, but updates to the optimal solution when it becomes available.

## Expected Outcomes

After completing this lesson, you should be able to:
- Implement real-time control systems with timing constraints
- Design optimization algorithms suitable for real-time applications
- Create adaptive systems that adjust their behavior based on computational resources
- Analyze the trade-offs between optimality and computational efficiency
- Evaluate real-time performance of control systems